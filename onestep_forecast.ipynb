{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M5 data generation for next task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "n_lags = 14 #number of lags or lookback window of the timeseries to use for prediction\n",
    "\"\"\"Please feel free to experiment with different values of n_lags\"\"\"\n",
    "\n",
    "#Function definitions\n",
    "def reshape_timeseries(y_series, n_lags):\n",
    "    \"\"\"\n",
    "    This function reshapes a timeseries into input-output pairs {Xtrain,ytrain}\n",
    "    y_series: input timeseries\n",
    "    n_lags: number of lags or lookback window of the timeseries\n",
    "    \"\"\"\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(n_lags, len(y_series)):\n",
    "        ar = y_series[i-n_lags: i]\n",
    "        X_train.append(ar)\n",
    "        y_train.append(y_series[i])\n",
    "    return np.array(X_train).reshape(-1,n_lags), np.array(y_train).reshape(-1,1)\n",
    "\n",
    "#Reading csv\n",
    "level12_data = pd.read_csv('sales_train_evaluation.csv', low_memory = False) #original dataset is at level 12 aggregation\n",
    "\n",
    "#Aggregation: group data for each of 10 different stores\n",
    "level3_data = level12_data.groupby('store_id').sum() #after grouping by store_id, we obtain data at level 3 aggregation\n",
    "\n",
    "#Dictionary comprehension to build input-output pairs in the form {X,y} from timeseries data for all stores\n",
    "data_dict = {store_id: reshape_timeseries(list(level3_data.loc[store_id,:].values), n_lags) for store_id in level3_data.index}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Example usage_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are $10$ different unique store_ids in the dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2',\n",
       "       'WI_3'],\n",
       "      dtype='object', name='store_id')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level3_data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reshaped data for all 10 stores are stored in the dictionary _data_dict_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are interested in the reshaped data for store 'CA_2', we use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_dict['CA_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are interested in the data for 'TX_3', we use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_dict['TX_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that {$X,y$} contain both training and validation examples. To get training and validation splits, you may use below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = X[0:-28, :], y[0:-28, :], X[-28:, :], y[-28:, :]\n",
    "# Validation is to be done on the last 28 days of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1899, 14), (1899, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 14), (28, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor as lgb\n",
    "from sklearn.metrics import mean_squared_error as MSE, mean_absolute_error as MAE, r2_score as R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA_1</th>\n",
       "      <td>0.820680</td>\n",
       "      <td>385.671730</td>\n",
       "      <td>304.971705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_2</th>\n",
       "      <td>0.786946</td>\n",
       "      <td>525.425365</td>\n",
       "      <td>426.964316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_3</th>\n",
       "      <td>0.795791</td>\n",
       "      <td>399.007473</td>\n",
       "      <td>310.060724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_4</th>\n",
       "      <td>0.372608</td>\n",
       "      <td>252.844423</td>\n",
       "      <td>199.242327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_1</th>\n",
       "      <td>0.239947</td>\n",
       "      <td>504.211696</td>\n",
       "      <td>357.129869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_2</th>\n",
       "      <td>0.412687</td>\n",
       "      <td>450.819057</td>\n",
       "      <td>321.472026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_3</th>\n",
       "      <td>0.296915</td>\n",
       "      <td>429.678230</td>\n",
       "      <td>342.235209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_1</th>\n",
       "      <td>0.615731</td>\n",
       "      <td>493.399962</td>\n",
       "      <td>383.517901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_2</th>\n",
       "      <td>0.259336</td>\n",
       "      <td>855.080991</td>\n",
       "      <td>634.295937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_3</th>\n",
       "      <td>0.579789</td>\n",
       "      <td>495.591349</td>\n",
       "      <td>400.397303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            R2        RMSE         MAE\n",
       "CA_1  0.820680  385.671730  304.971705\n",
       "CA_2  0.786946  525.425365  426.964316\n",
       "CA_3  0.795791  399.007473  310.060724\n",
       "CA_4  0.372608  252.844423  199.242327\n",
       "TX_1  0.239947  504.211696  357.129869\n",
       "TX_2  0.412687  450.819057  321.472026\n",
       "TX_3  0.296915  429.678230  342.235209\n",
       "WI_1  0.615731  493.399962  383.517901\n",
       "WI_2  0.259336  855.080991  634.295937\n",
       "WI_3  0.579789  495.591349  400.397303"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for store_id in level3_data.index:\n",
    "    \n",
    "    #Getting store X,y data\n",
    "    X, y = data_dict[store_id]  \n",
    "    X_train, y_train, X_val, y_val = X[0:-28, :], y[0:-28, :], X[-28:, :], y[-28:, :]\n",
    "    # Validation is to be done on the last 28 days of data\n",
    "    \n",
    "    #Fitting gradient boosted tree\n",
    "    lgbm = lgb(random_state=42).fit(X_train, y_train.flatten())\n",
    "    y_pred = lgbm.predict(X_val)\n",
    "    \n",
    "    # Error metrics\n",
    "    r2 = R2(y_val, y_pred)\n",
    "    rmse = MSE(y_val, y_pred, squared=False)\n",
    "    mae = MAE(y_val, y_pred)\n",
    "    results.append([r2, rmse, mae])\n",
    "    \n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.rename(index={results_df.index[i]: level3_data.index[i] for i in range(10)}, columns={0: 'R2', 1: 'RMSE', 2: 'MAE'})\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root mean squared scaled error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6982853341723568"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denom = np.mean(np.diff(y_train.flatten())**2)\n",
    "rmsse = np.sqrt(MSE(y_val, y_pred)/denom)\n",
    "rmsse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(y_t - y_{t-1})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean results: [  0.71116301 479.1730277    0.51804304 368.02873171]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA_1</th>\n",
       "      <td>0.445352</td>\n",
       "      <td>385.671730</td>\n",
       "      <td>0.820680</td>\n",
       "      <td>304.971705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_2</th>\n",
       "      <td>0.693159</td>\n",
       "      <td>525.425365</td>\n",
       "      <td>0.786946</td>\n",
       "      <td>426.964316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_3</th>\n",
       "      <td>0.414798</td>\n",
       "      <td>399.007473</td>\n",
       "      <td>0.795791</td>\n",
       "      <td>310.060724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_4</th>\n",
       "      <td>0.798875</td>\n",
       "      <td>252.844423</td>\n",
       "      <td>0.372608</td>\n",
       "      <td>199.242327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_1</th>\n",
       "      <td>0.844677</td>\n",
       "      <td>504.211696</td>\n",
       "      <td>0.239947</td>\n",
       "      <td>357.129869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_2</th>\n",
       "      <td>0.591245</td>\n",
       "      <td>450.819057</td>\n",
       "      <td>0.412687</td>\n",
       "      <td>321.472026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_3</th>\n",
       "      <td>0.752239</td>\n",
       "      <td>429.678230</td>\n",
       "      <td>0.296915</td>\n",
       "      <td>342.235209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_1</th>\n",
       "      <td>0.688044</td>\n",
       "      <td>493.399962</td>\n",
       "      <td>0.615731</td>\n",
       "      <td>383.517901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_2</th>\n",
       "      <td>1.188165</td>\n",
       "      <td>855.080991</td>\n",
       "      <td>0.259336</td>\n",
       "      <td>634.295937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_3</th>\n",
       "      <td>0.695075</td>\n",
       "      <td>495.591349</td>\n",
       "      <td>0.579789</td>\n",
       "      <td>400.397303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RMSSE        RMSE        R2         MAE\n",
       "CA_1  0.445352  385.671730  0.820680  304.971705\n",
       "CA_2  0.693159  525.425365  0.786946  426.964316\n",
       "CA_3  0.414798  399.007473  0.795791  310.060724\n",
       "CA_4  0.798875  252.844423  0.372608  199.242327\n",
       "TX_1  0.844677  504.211696  0.239947  357.129869\n",
       "TX_2  0.591245  450.819057  0.412687  321.472026\n",
       "TX_3  0.752239  429.678230  0.296915  342.235209\n",
       "WI_1  0.688044  493.399962  0.615731  383.517901\n",
       "WI_2  1.188165  855.080991  0.259336  634.295937\n",
       "WI_3  0.695075  495.591349  0.579789  400.397303"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for store_id in level3_data.index:\n",
    "    #Getting store X,y data\n",
    "    X, y = data_dict[store_id]  \n",
    "    X_train, y_train, X_val, y_val = X[0:-28, :], y[0:-28, :], X[-28:, :], y[-28:, :]\n",
    "    # Validation is to be done on the last 28 days of data\n",
    "    \n",
    "    #RMSSE denominator\n",
    "    ytrain = level3_data.loc[store_id,:].values[0:-28]\n",
    "    denom = np.mean(np.diff(ytrain.flatten())**2)\n",
    "    \n",
    "    #Fitting gradient boosted tree\n",
    "    lgbm = lgb(random_state=42).fit(X_train, y_train.flatten())\n",
    "    y_pred = lgbm.predict(X_val)\n",
    "    \n",
    "    # Error metrics\n",
    "    rmsse = np.sqrt(MSE(y_val, y_pred)/denom)\n",
    "    r2 = R2(y_val, y_pred)\n",
    "    rmse = MSE(y_val, y_pred, squared=False)\n",
    "    mae = MAE(y_val, y_pred)\n",
    "    \n",
    "    results.append([rmsse, rmse, r2, mae])\n",
    "    \n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.rename(index={results_df.index[i]: level3_data.index[i] for i in range(10)}, columns={0: 'RMSSE', 1: 'RMSE', 2: 'R2', 3:'MAE'})\n",
    "print('mean results:', np.mean(results_df.values, axis=0))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#Alternatively use Bayesian optimisation (hyperopt) if grid space is too large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(lgb(random_state=42), \n",
    "param_grid={\\\n",
    "'learning_rate': [0.001, 0.01, 0.1], \\\n",
    "'num_leaves': [31, 40, 50], \\\n",
    "#'boosting_type': ['gbdt','dart'], \n",
    "#'max_depth': [-1, 4], \\\n",
    "#'subsample':[0.5,0.8,1], \\\n",
    "'colsample_bytree':[0.5,0.8,1], \\\n",
    "#'reg_alpha': [0,0.1], \\\n",
    "#'reg_lambda': [0,0.1]\n",
    "}, \\\n",
    "scoring='neg_median_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA_1\n",
      "CA_2\n",
      "CA_3\n",
      "CA_4\n",
      "TX_1\n",
      "TX_2\n",
      "TX_3\n",
      "WI_1\n",
      "WI_2\n",
      "WI_3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA_1</th>\n",
       "      <td>0.445352</td>\n",
       "      <td>385.671730</td>\n",
       "      <td>0.820680</td>\n",
       "      <td>304.971705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_2</th>\n",
       "      <td>0.693159</td>\n",
       "      <td>525.425365</td>\n",
       "      <td>0.786946</td>\n",
       "      <td>426.964316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_3</th>\n",
       "      <td>0.435326</td>\n",
       "      <td>418.753933</td>\n",
       "      <td>0.775079</td>\n",
       "      <td>323.570944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA_4</th>\n",
       "      <td>0.798875</td>\n",
       "      <td>252.844423</td>\n",
       "      <td>0.372608</td>\n",
       "      <td>199.242327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_1</th>\n",
       "      <td>0.844677</td>\n",
       "      <td>504.211696</td>\n",
       "      <td>0.239947</td>\n",
       "      <td>357.129869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_2</th>\n",
       "      <td>0.597484</td>\n",
       "      <td>455.576428</td>\n",
       "      <td>0.400226</td>\n",
       "      <td>313.371144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX_3</th>\n",
       "      <td>0.797469</td>\n",
       "      <td>455.513265</td>\n",
       "      <td>0.209825</td>\n",
       "      <td>361.860591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_1</th>\n",
       "      <td>0.688044</td>\n",
       "      <td>493.399962</td>\n",
       "      <td>0.615731</td>\n",
       "      <td>383.517901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_2</th>\n",
       "      <td>1.175351</td>\n",
       "      <td>845.858998</td>\n",
       "      <td>0.275226</td>\n",
       "      <td>617.451092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI_3</th>\n",
       "      <td>0.695075</td>\n",
       "      <td>495.591349</td>\n",
       "      <td>0.579789</td>\n",
       "      <td>400.397303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RMSSE        RMSE        R2         MAE\n",
       "CA_1  0.445352  385.671730  0.820680  304.971705\n",
       "CA_2  0.693159  525.425365  0.786946  426.964316\n",
       "CA_3  0.435326  418.753933  0.775079  323.570944\n",
       "CA_4  0.798875  252.844423  0.372608  199.242327\n",
       "TX_1  0.844677  504.211696  0.239947  357.129869\n",
       "TX_2  0.597484  455.576428  0.400226  313.371144\n",
       "TX_3  0.797469  455.513265  0.209825  361.860591\n",
       "WI_1  0.688044  493.399962  0.615731  383.517901\n",
       "WI_2  1.175351  845.858998  0.275226  617.451092\n",
       "WI_3  0.695075  495.591349  0.579789  400.397303"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for store_id in level3_data.index:\n",
    "    print(store_id)\n",
    "    #Getting store X,y data\n",
    "    X, y = data_dict[store_id]  \n",
    "    X_train, y_train, X_val, y_val = X[0:-28, :], y[0:-28, :], X[-28:, :], y[-28:, :]\n",
    "    # Validation is to be done on the last 28 days of data\n",
    "    \n",
    "    #RMSSE denominator\n",
    "    ytrain = level3_data.loc[store_id,:].values[0:-28]\n",
    "    denom = np.mean(np.diff(ytrain.flatten())**2)\n",
    "    \n",
    "    #Fitting gradient boosted tree\n",
    "    grid = GridSearchCV(lgb(random_state=42), \n",
    "    param_grid={\\\n",
    "    'learning_rate': [0.001, 0.01, 0.1], \\\n",
    "    'num_leaves': [31, 40, 50], \\\n",
    "    #'boosting_type': ['gbdt','dart'], \n",
    "    #'max_depth': [-1, 4], \\\n",
    "    'subsample':[0.5,0.8,1], \\\n",
    "    #'colsample_bytree':[0.5,0.8,1], \\\n",
    "    #'reg_alpha': [0,0.1], \\\n",
    "    #'reg_lambda': [0,0.1]\n",
    "    }, \\\n",
    "    scoring='neg_mean_absolute_error')\n",
    "    grid.fit(X_train, y_train.flatten())\n",
    "    lgbm = grid.best_estimator_\n",
    "    y_pred = lgbm.predict(X_val)\n",
    "    \n",
    "    # Error metrics\n",
    "    # Error metrics\n",
    "    rmsse = np.sqrt(MSE(y_val, y_pred)/denom)\n",
    "    r2 = R2(y_val, y_pred)\n",
    "    rmse = MSE(y_val, y_pred, squared=False)\n",
    "    mae = MAE(y_val, y_pred)\n",
    "    \n",
    "    results.append([rmsse, rmse, r2, mae])\n",
    "    \n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.rename(index={results_df.index[i]: level3_data.index[i] for i in range(10)}, columns={0: 'RMSSE', 1: 'RMSE', 2: 'R2', 3:'MAE'})\n",
    "\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarise timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-5ba8527091f5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-5ba8527091f5>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    original series: 10, 100, 120, 140, 160, 200, 210, 240\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "original series: 10, 100, 120, 140, 160, 200, 210, 240\n",
    "\n",
    "differenced: 90, 20, 20, 20, 40, 10, 30\n",
    "    \n",
    "    -70, 0, 0, 20, -30, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(level3_data.loc['WI_3',:].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregation: group data for each of 10 different stores\n",
    "level3_data = level12_data.groupby('store_id').sum() #after grouping by store_id, we obtain data at level 3 aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller(level3_data.loc['CA_1',:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(original_series): \n",
    "    \"\"\"\n",
    "    This function tests for stationarity on the timeseries using the augmented Dickey-Fuller test.\n",
    "    Non-stationary timeseries are differenced incrementally, and the stationarity test performed.\n",
    "    \n",
    "    original_series: input original timeseries data\n",
    "    stationary_series: output stationary timeseries\n",
    "    first_values: first values of the timeseries required to recover the original series; \n",
    "    the length of first_values is equal to the differencing order\n",
    "    \"\"\"\n",
    "    first_values = []; stationary_series = original_series\n",
    "    for i in range(0, 11):\n",
    "        if i == 0:\n",
    "            series_to_test = original_series\n",
    "        else:\n",
    "            series_to_test = series_to_test.diff(1)[1:]\n",
    "        first_values.append(series_to_test.iloc[0])\n",
    "        stat_result = adfuller(series_to_test) #Check stationarity\n",
    "        pval = stat_result[1] #p-value\n",
    "        if pval <= 0.05:\n",
    "            stationary_series = series_to_test\n",
    "            break       \n",
    "    first_values = np.flip(first_values[0:-1])\n",
    "    return stationary_series, first_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate(differenced_series, first_values): \n",
    "    \"\"\"\n",
    "    This function reverse-differences a differenced timeseries to recover the original timseries\n",
    "    \n",
    "    differenced_series: input differenced timeseries\n",
    "    original_series: output original timeseries\n",
    "    \"\"\"\n",
    "    diff_order = len(first_values)\n",
    "    original_series = differenced_series.flatten()\n",
    "    if diff_order == 0:\n",
    "        original_series = differenced_series.flatten()\n",
    "    else:\n",
    "        for i in range(diff_order):\n",
    "            original_series = np.column_stack((first_values[i].reshape(1,1), (np.cumsum(original_series) \\\n",
    "              + first_values[i]).reshape(1,-1))).flatten()      \n",
    "    return original_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for store_id in level3_data.index:\n",
    "    print(store_id)\n",
    "    \n",
    "    # Stationarise timeseries\n",
    "    stationary_series, first_values = difference(level3_data.loc[store_id,:])\n",
    "    print('differencing order', len(first_values))\n",
    "    \n",
    "    # Reshaping timeseries into X,y pairs\n",
    "    X, y = reshape_timeseries(list(stationary_series), n_lags)\n",
    "    X_train, y_train, X_val, _ = X[0:-28, :], y[0:-28, :], X[-28:, :], y[-28:, :]\n",
    "    y_val = level3_data.loc[store_id,:].values[-28:]\n",
    "     \n",
    "    #RMSSE denominator\n",
    "    ytrain = level3_data.loc[store_id,:].values[0:-28]\n",
    "    denom = np.mean(np.diff(ytrain.flatten())**2)\n",
    "    \n",
    "    #Fitting gradient boosted tree\n",
    "    lgbm = lgb(random_state=42).fit(X_train, y_train.flatten())\n",
    "    y_hat = lgbm.predict(X_val)\n",
    "    \n",
    "    # Recover original series (integrate)\n",
    "    y_pred = level3_data.loc[store_id,:].values[-29:-1] + y_hat\n",
    "    \n",
    "    # Error metrics\n",
    "    rmsse = np.sqrt(MSE(y_val, y_pred)/denom)\n",
    "    r2 = R2(y_val, y_pred)\n",
    "    rmse = MSE(y_val, y_pred, squared=False)\n",
    "    mae = MAE(y_val, y_pred)\n",
    "    \n",
    "    results.append([rmsse, rmse, r2, mae])\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.rename(index={results_df.index[i]: level3_data.index[i] for i in range(10)}, columns={0: 'RMSSE', 1: 'RMSE', 2: 'R2', 3:'MAE'})\n",
    "print('mean results:', np.mean(results_df.values, axis=0))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stationarised timeseries example (WI_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stationary_series.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn across all series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA1: \n",
    "CA2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = pd.DataFrame()\n",
    "ytrain = pd.DataFrame()\n",
    "Xval = pd.DataFrame()\n",
    "yval = pd.DataFrame()\n",
    "store_count = 0\n",
    "for store_id in level3_data.index:\n",
    "    X, y = data_dict[store_id]\n",
    "    X_train, y_train, X_val, y_val = X[0:-28, :], y[0:-28, :], X[-28:, :], y[-28:, :]\n",
    "    \n",
    "    if store_id.split('_')[0] == 'CA':\n",
    "        state_id = 1\n",
    "    elif store_id.split('_')[0] == 'TX':\n",
    "        state_id = 2\n",
    "    elif store_id.split('_')[0] == 'WI':\n",
    "        state_id = 3\n",
    "    \n",
    "    X_train = np.column_stack((store_count*np.ones([X_train.shape[0],1],dtype='int64'), state_id*np.ones([X_train.shape[0],1],dtype='int64'), X_train))\n",
    "    X_val = np.column_stack((store_count*np.ones([X_val.shape[0],1],dtype='int64'), state_id*np.ones([X_val.shape[0],1],dtype='int64'), X_val))\n",
    "    \n",
    "    Xtrain = pd.concat([Xtrain, pd.DataFrame(X_train)])\n",
    "    ytrain = pd.concat([ytrain, pd.DataFrame(y_train)])\n",
    "    \n",
    "    Xval = pd.concat([Xval, pd.DataFrame(X_val)])\n",
    "    yval = pd.concat([yval, pd.DataFrame(y_val)])\n",
    "    \n",
    "    store_count = store_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_train = pd.get_dummies(Xtrain.iloc[:,[0,1]], columns=[0,1], drop_first=True)\n",
    "Xtrain = pd.concat([exog_train, Xtrain], axis=1, join='inner')\n",
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_val = pd.get_dummies(Xval.iloc[:,[0,1]], columns=[0,1], drop_first=True)\n",
    "Xval = pd.concat([exog_val,Xval], axis=1, join='inner')\n",
    "Xval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting gradient boosted tree\n",
    "lgbm = lgb(random_state=42).fit(Xtrain, ytrain)\n",
    "yhat = lgbm.predict(Xval)\n",
    "YHAT = yhat.reshape(10,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error metrics\n",
    "results = []\n",
    "for i in range(10):\n",
    "    #RMSSE denominator\n",
    "    store_id = level3_data.index[i]\n",
    "    X, y = data_dict[store_id]\n",
    "    X_train, y_train, X_val, y_val = X[0:-28, :], y[0:-28, :], X[-28:, :], y[-28:, :]\n",
    "    \n",
    "    ytrain = level3_data.loc[store_id,:].values[0:-28]\n",
    "    denom = np.mean(np.diff(ytrain.flatten())**2)\n",
    "    \n",
    "    y_pred = YHAT[i,:]\n",
    "    # Error metrics\n",
    "    rmsse = np.sqrt(MSE(y_val, y_pred)/denom)\n",
    "    r2 = R2(y_val, y_pred)\n",
    "    rmse = MSE(y_val, y_pred, squared=False)\n",
    "    mae = MAE(y_val, y_pred) \n",
    "    results.append([rmsse, rmse, r2, mae])\n",
    "    \n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.rename(index={results_df.index[i]: level3_data.index[i] for i in range(10)}, columns={0: 'RMSSE', 1: 'RMSE', 2: 'R2', 3:'MAE'})\n",
    "print('mean results:', np.mean(results_df.values, axis=0))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = pd.DataFrame()\n",
    "ytrain = pd.DataFrame()\n",
    "Xval = pd.DataFrame()\n",
    "yval = pd.DataFrame()\n",
    "store_count = 0\n",
    "for store_id in level3_data.index:\n",
    "    \n",
    "     # Stationarise timeseries\n",
    "    stationary_series, first_values = difference(level3_data.loc[store_id,:])\n",
    "    print('differencing order', len(first_values))\n",
    "    \n",
    "    # Reshaping timeseries into X,y pairs\n",
    "    X, y = reshape_timeseries(list(stationary_series), n_lags)\n",
    "    X_train, y_train, X_val, _ = X[0:-28, :], y[0:-28, :], X[-28:, :], y[-28:, :]\n",
    "    y_val = level3_data.loc[store_id,:].values[-28:]\n",
    "    \n",
    "    \n",
    "    if store_id.split('_')[0] == 'CA':\n",
    "        state_id = 1\n",
    "    elif store_id.split('_')[0] == 'TX':\n",
    "        state_id = 2\n",
    "    elif store_id.split('_')[0] == 'WI':\n",
    "        state_id = 3\n",
    "    \n",
    "    X_train = np.column_stack((store_count*np.ones([X_train.shape[0],1],dtype='int64'), state_id*np.ones([X_train.shape[0],1],dtype='int64'), X_train))\n",
    "    X_val = np.column_stack((store_count*np.ones([X_val.shape[0],1],dtype='int64'), state_id*np.ones([X_val.shape[0],1],dtype='int64'), X_val))\n",
    "    \n",
    "    Xtrain = pd.concat([Xtrain, pd.DataFrame(X_train)])\n",
    "    ytrain = pd.concat([ytrain, pd.DataFrame(y_train)])\n",
    "    \n",
    "    Xval = pd.concat([Xval, pd.DataFrame(X_val)])\n",
    "    yval = pd.concat([yval, pd.DataFrame(y_val)])\n",
    "    \n",
    "    store_count = store_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting gradient boosted tree\n",
    "grid = GridSearchCV(lgb(random_state=42), \n",
    "param_grid={\\\n",
    "'learning_rate': [0.001, 0.01, 0.1], \\\n",
    "'num_leaves': [31, 40, 50], \\\n",
    "#'boosting_type': ['gbdt','dart'], \n",
    "#'max_depth': [-1, 4], \\\n",
    "'subsample':[0.5,0.8,1], \\\n",
    "#'colsample_bytree':[0.5,0.8,1], \\\n",
    "#'reg_alpha': [0,0.1], \\\n",
    "#'reg_lambda': [0,0.1]\n",
    "}, \\\n",
    "scoring='neg_mean_absolute_error')\n",
    "grid.fit(Xtrain, ytrain)\n",
    "lgbm = grid.best_estimator_\n",
    "yhat = lgbm.predict(Xval)\n",
    "YHAT = yhat.reshape(10,28)\n",
    "YVAL = yval.values.reshape(10,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error metrics\n",
    "results = []\n",
    "for i in range(10):\n",
    "    #RMSSE denominator\n",
    "    store_id = level3_data.index[i]\n",
    "    X, y = data_dict[store_id]\n",
    "    \n",
    "    ytrain = level3_data.loc[store_id,:].values[0:-28]\n",
    "    denom = np.mean(np.diff(ytrain.flatten())**2)\n",
    "    \n",
    "    y_pred = YHAT[i,:] + level3_data.loc[store_id,:].values[-29:-1]\n",
    "    y_val = YVAL[i,:]\n",
    "    # Error metrics\n",
    "    rmsse = np.sqrt(MSE(y_val, y_pred)/denom)\n",
    "    r2 = R2(y_val, y_pred)\n",
    "    rmse = MSE(y_val, y_pred, squared=False)\n",
    "    mae = MAE(y_val, y_pred)\n",
    "    results.append([rmsse, rmse, r2, mae])\n",
    "    \n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.rename(index={results_df.index[i]: level3_data.index[i] for i in range(10)}, columns={0: 'RMSSE', 1: 'RMSE', 2: 'R2', 3:'MAE'})\n",
    "print('mean results:', np.mean(results_df.values, axis=0))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multistep prediction (Next steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3 /45, 101, 0, 7, 8\n",
    "\n",
    "1,2,3 -- 4\n",
    "2,3,4 -- 5\n",
    "...\n",
    "\n",
    "0,1,2 -- 3\n",
    "\n",
    "test example:\n",
    "1,2,3 -- x= 44/ 45\n",
    "\n",
    "2,3,44 -- x= 95/ 101\n",
    "3,44,95 -- x = -12/ 0\n",
    "44,95,-12 -- x=23 /7\n",
    "\n",
    "\n",
    "45,101,0 -- 7/ 6.5\n",
    "101,0,7 -- 8/ 8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF-DiffNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I'm trying out a network I developed on the M5 problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import binom, factorial\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import pmdarima as pm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error as MAE, mean_squared_error as MSE\n",
    "from sklearn.linear_model import LassoCV, LinearRegression as LR\n",
    "\n",
    "#Set random seed\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variableBetas(X, c):\n",
    "    \"\"\"\n",
    "    The function returns c RBF centres and widths using K-Means clustering, with each RBF having its own unique width.\n",
    "    \n",
    "    X: input matrix of size n-by-d, where n is the number of training examples, and d is the number of features\n",
    "    c: the number of RBF centres\n",
    "    centres: output of size c-by-d\n",
    "    betas: output of size 1-by-d\n",
    "    \"\"\"\n",
    "    clusterObj = KMeans(n_clusters = c, random_state = 42).fit(X)\n",
    "    labels = clusterObj.labels_\n",
    "    p = 10\n",
    "    betas = []\n",
    "    centres = []\n",
    "    for label in np.unique(labels):\n",
    "        Xk = X[labels == label, :]\n",
    "        Muk = np.mean(Xk, axis=0)\n",
    "        tree = KDTree(Xk)\n",
    "        dref, iref = tree.query(np.mean(Xk, axis=0).reshape(1,-1), p)\n",
    "        #Muk = Xk[iref[0],:]\n",
    "        #sigma = np.mean(np.linalg.norm(Xk - Muk, axis = 1), axis = 0)\n",
    "        sigma = np.mean(dref)\n",
    "        betas.append(1/(2*sigma**2))\n",
    "        centres.append(Muk)      \n",
    "    centres = np.array(centres)\n",
    "    betas = np.array(betas); betas[np.isinf(betas)] = np.sum(betas[np.isinf(betas)==False])\n",
    "    return centres, betas\n",
    "\n",
    "def rbf(X, centres, betas):\n",
    "    \"\"\"\n",
    "    This function evaluates the radial basis function (RBF) Phi for each data sample in X.\n",
    "    \n",
    "    X: input matrix of size N-by-d, where N is the number of training examples, and d is the number of features\n",
    "    centres: input array of RBF locations of size: c-by-dy, where c is the number of centres\n",
    "    betas: input array of RBF widths of size: 1-by-d\n",
    "    Phi: an output array of size N-by-c\n",
    "    \"\"\"\n",
    "    N, d = X.shape \n",
    "    Phi = [np.exp(-betas* np.linalg.norm(X[n] - centres, axis = 1)**2) for n in range(N)]  \n",
    "    return np.array(Phi)\n",
    "\n",
    "def trainRBFN(Xtrain, ytrain, c, normalise): \n",
    "    \"\"\"\n",
    "    This function trains the weights for the normalised and unnormalised RBF networks\n",
    "    \n",
    "    Xtrain: training input of size n_train-by-d\n",
    "    ytrain: training output of size n_train-by-1\n",
    "    c: number of radial basis function (RBF) centres\n",
    "    normalise: a Boolean input indicating normalised RBF network (True) or unnormalised RBF network (False)\n",
    "    outputs: linear model at output layer, together with the RBF centres and widths \n",
    "    \"\"\"\n",
    "    n, d = Xtrain.shape \n",
    "    centres, betas = variableBetas(Xtrain, c)\n",
    "    Phi = rbf(Xtrain, centres, betas)    \n",
    "    if normalise == True:\n",
    "        Phi = Phi/ np.sum(Phi, axis = 1).reshape(-1,1)\n",
    "    linMdl = LassoCV().fit(Phi, ytrain)\n",
    "    mse = MSE(linMdl.predict(Phi), ytrain)\n",
    "    return linMdl, centres, betas\n",
    "\n",
    "def testRBFN(Xtest, centres, betas, linMdl, normalise):\n",
    "    \"\"\"\n",
    "    This function tests the normalised/unnormalised RBF network on new samples\n",
    "    \n",
    "    Xtest: test input of size n_test-by-d\n",
    "    centres: input array of RBF locations of size: c-by-d, where c is the number of centres\n",
    "    betas: input array of RBF widths of size: 1-by-d\n",
    "    linMdl: linear model at output layer of RBF network\n",
    "    normalise: a Boolean input indicating normalised RBF network (True) or unnormalised RBF network (False)\n",
    "    outputs: one step predictions of size: n_test-by-1 - for the sequence \n",
    "    \"\"\"\n",
    "    n, d = Xtest.shape\n",
    "    Phi = rbf(Xtest, centres, betas)\n",
    "    if normalise == True:\n",
    "        Phi = Phi/ np.sum(Phi, axis = 1).reshape(-1,1)    \n",
    "    ypred = linMdl.predict(Phi)  \n",
    "    return ypred   \n",
    "\n",
    "def rbfderivatives(X, centres, betas, order, Phi):\n",
    "    \"\"\"\n",
    "    This function evaluates the radial basis function (RBF) derivatives with respect to each component of x \n",
    "    up to a differential order of \"order\", where x is given by each row of X.\n",
    "    \n",
    "    X: input matrix of size N-by-d, where N is the number of training examples, and d is the number of features\n",
    "    centres: input array of RBF locations of size: c-by-dy, where c is the number of centres\n",
    "    betas: input array of RBF widths of size: 1-by-d\n",
    "    Phi: input array of radial basis functions of size N-by-c\n",
    "    order: input scalar representing the order of the differential equation\n",
    "    diPhi: output array of RBF derivatives of size: N-by-order-by-d-by-c\n",
    "    \"\"\"\n",
    "    N, d = X.shape\n",
    "    c = centres.shape[0]\n",
    "    diPhi = []\n",
    "    for n in range(N): \n",
    "        diPhi_n = []\n",
    "        diPhi_n.append(np.tile(Phi[n], (d, 1))) \n",
    "        for i in range(1, order+1):          \n",
    "            leibniz_sum = 0    \n",
    "            for k in range(i):       \n",
    "                bin_coeff = binom(i-1,k)               \n",
    "                if i-k-1 == 0:\n",
    "                    u = (-2*betas.reshape(-1,1)*(X[n]-centres)).T\n",
    "                elif i-k-1 == 1:\n",
    "                    u = (-2*betas.reshape(-1,1)* np.ones([c, d])).T\n",
    "                elif i-k-1 >= 2:\n",
    "                    u = np.zeros([d, c])             \n",
    "                leibniz_sum = leibniz_sum + (bin_coeff* u* diPhi_n[k])         \n",
    "            diPhi_n.append(leibniz_sum)         \n",
    "        diPhi.append(diPhi_n[1:]) #Excluding the zeroth derivative\n",
    "    return np.array(diPhi)\n",
    "\n",
    "def obj_func(x, extraArgs):\n",
    "    \"\"\"\n",
    "    The function evaluates the loss function for training the differential RBF network weights.\n",
    "    \n",
    "    x: initial solution of weights to optimise\n",
    "    extraArgs: extra arguments to compute loss function\n",
    "    output: loss function value\n",
    "    \"\"\"\n",
    "    diPhi = extraArgs[0]\n",
    "    y = extraArgs[1]\n",
    "    ylagged = extraArgs[2]\n",
    "    n, _, c = diPhi.shape\n",
    "    nlags = ylagged.shape[1]  \n",
    "    w_lagged = x[0:nlags].reshape(-1,1)\n",
    "    rbf_coeffs = x[nlags:nlags+c].reshape(-1,1)    \n",
    "    pde_coeffs = x[nlags+c:].reshape(-1,1)\n",
    "    ypred = ((np.sum(pde_coeffs.reshape(1, len(pde_coeffs),1)*diPhi, axis=1))@rbf_coeffs) + ylagged@w_lagged\n",
    "    return MSE(y, ypred)\n",
    "\n",
    "def trainRBFDiffNet(Xtrain, ytrain, c, nlags, order): #This function trains the proposed RBF network\n",
    "    \"\"\"\n",
    "    This function trains the differential RBF network (RBF-DiffNet)\n",
    "    \n",
    "    Xtrain: training input of size n_train-by-d\n",
    "    ytrain: training output of size n_train-by-1\n",
    "    c: number of radial basis function (RBF) centres\n",
    "    nlags: number of lags or lookback window of the timeseries\n",
    "    order: order of the partial differential equation\n",
    "    outputs: network weights together with the RBF centres and widths\n",
    "    \"\"\"\n",
    "    n_train, d = Xtrain.shape\n",
    "    centres, betas = variableBetas(Xtrain, c)\n",
    "\n",
    "    ylagged = Xtrain[:,-nlags:]\n",
    "    if nlags == 1:\n",
    "        ylagged = ylagged.reshape(-1,1)\n",
    "    Phi = rbf(Xtrain, centres, betas)\n",
    "    diPhi = rbfderivatives(Xtrain, centres, betas, order, Phi).reshape([n_train, order*d, c])\n",
    "\n",
    "    rbfMdl = LR(fit_intercept=True).fit(Phi, ytrain)\n",
    "    #rbfMdl = LassoCV(fit_intercept=True).fit(Phi, ytrain)\n",
    "    rbf_coeffs = rbfMdl.coef_.reshape(-1,1)\n",
    "    bias = rbfMdl.intercept_\n",
    "    w_lagged = np.ones([nlags,1])/nlags\n",
    "    #pde_coeffs = np.zeros([order*d,1])\n",
    "    pde_coeffs = (np.ones([order, d])*(0.1**np.arange(1,order+1)/factorial(np.arange(1,order+1))).reshape(-1,1)).reshape(-1,1)\n",
    "    ytrain = ytrain.reshape(-1,1)\n",
    "    \n",
    "    ypred = ((np.sum(pde_coeffs.reshape(1, len(pde_coeffs),1)*diPhi, axis=1))@rbf_coeffs) + ylagged@w_lagged\n",
    "    min_err = MSE(ytrain, ypred)\n",
    "    opt_weights = [rbf_coeffs, pde_coeffs, w_lagged, bias]\n",
    "    \n",
    "    num_iter = 100\n",
    "    for i in range(num_iter):\n",
    "        #print(i)\n",
    "        #Step 1: Fix w_lagged, rbf_coeffs; solve for pde_coeffs\n",
    "        pde_coeffs = np.linalg.pinv((np.sum(rbf_coeffs.reshape(1,1,c)*diPhi, axis=2)))@(ytrain - ylagged@w_lagged)\n",
    "\n",
    "        #Step 2: Fix rbf_coeffs, pde_coeffs; solve for w_lagged\n",
    "        w_lagged = np.linalg.pinv(ylagged)@(ytrain - ((np.sum(pde_coeffs.reshape(1, len(pde_coeffs),1)*diPhi, axis=1))@rbf_coeffs))\n",
    "\n",
    "        #Step 3: Fix w_lagged, pde_coeffs; solve for rbf_coeffs\n",
    "        rbf_coeffs = np.linalg.pinv((np.sum(pde_coeffs.reshape(1, len(pde_coeffs),1)*diPhi, axis=1)))@(ytrain - ylagged@w_lagged)\n",
    "         \n",
    "        bias = np.mean(ytrain - Phi@rbf_coeffs)\n",
    "        \n",
    "        #Compute predictions and errors\n",
    "        ypred = ((np.sum(pde_coeffs.reshape(1, len(pde_coeffs),1)*diPhi, axis=1))@rbf_coeffs) + ylagged@w_lagged\n",
    "        err = MSE(ytrain, ypred)\n",
    "        \n",
    "        if err < min_err:\n",
    "            min_err = err\n",
    "            opt_weights = [rbf_coeffs, pde_coeffs, w_lagged, bias]\n",
    "\n",
    "    return opt_weights, centres, betas\n",
    "\n",
    "def testRBFDiffNet(Xtest, weights, centres, betas):\n",
    "    \"\"\"\n",
    "    This function tests the differential RBF network on new samples\n",
    "    \n",
    "    Xtest: test input of size n_test-by-d\n",
    "    weights: differential RBF network weights\n",
    "    centres: input array of RBF locations of size: c-by-d, where c is the number of centres\n",
    "    betas: input array of RBF widths of size: 1-by-d\n",
    "    order: order of the partial differential equation\n",
    "    outputs: one step predictions of size: n_test-by-1 - for the sequence \n",
    "    \"\"\"\n",
    "    [rbf_coeffs, pde_coeffs, w_lagged, bias] = weights\n",
    "    c = len(betas)\n",
    "    n_test, d = Xtest.shape\n",
    "    order = int(len(pde_coeffs)/d)\n",
    "    nlags = len(w_lagged)\n",
    "    ylagged = Xtest[:,-nlags:]  \n",
    "    Phi = rbf(Xtest, centres, betas)   \n",
    "    diPhi = rbfderivatives(Xtest, centres, betas, order, Phi).reshape([n_test, order*d, c])\n",
    "    ypred = ((np.sum(pde_coeffs.reshape(1, len(pde_coeffs),1)*diPhi, axis=1))@rbf_coeffs) + ylagged@w_lagged\n",
    "    #ypred = Phi@rbf_coeffs + bias\n",
    "    return ypred\n",
    "\n",
    "\n",
    "def one_step_predict(algorithm):\n",
    "    \"\"\"\n",
    "    This function provides one-step predictions for a timeseries\n",
    "\n",
    "    algorithm: an input string indicating what algorithm is being used for the predictions\n",
    "    yhat: onestep predictions\n",
    "    \"\"\"\n",
    "    ytest_scaled = scaler.transform(ytest.reshape(-1,1))\n",
    "    ylist = list(ytrain_scaled.flatten()) + list(ytest_scaled.flatten())\n",
    "    ylagged, ynext = reshape_timeseries(ylist, nlags)\n",
    "    X_test = ylagged[-num_test:, :].reshape(num_test, -1)\n",
    "\n",
    "    if algorithm == 'proposed':\n",
    "        ypred = testRBFDiffNet(X_test, weights, centres, betas)\n",
    "    elif algorithm == 'urbfn':\n",
    "        ypred = testRBFN(X_test, centres_u, betas_u, rbfMdl_u, False)  \n",
    "    elif algorithm == 'nrbfn':\n",
    "        ypred = testRBFN(X_test, centres_n, betas_n, rbfMdl_n, True)\n",
    "    yhat = scaler.inverse_transform(ypred.reshape(-1,1))\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 28\n",
    "nlags = 14\n",
    "order_opt = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for store_id in level3_data.index:\n",
    "    print('training ', store_id)\n",
    "    \n",
    "    #Getting store X,y data\n",
    "    X, y = data_dict[store_id]  \n",
    "    X_train, y_train, X_val, y_val = X[0:-28, :], y[0:-28, :], X[-28:, :], y[-28:, :]\n",
    "    # Validation is to be done on the last 28 days of data\n",
    "    \n",
    "    #RMSSE denominator\n",
    "    ytrain = level3_data.loc[store_id,:].values[0:-28]\n",
    "    denom = np.mean(np.diff(ytrain.flatten())**2)\n",
    "     \n",
    "    \n",
    "    # Fit RBF-DiffNet\n",
    "    weights, centres, betas = trainRBFDiffNet(X_train, y_train, c, nlags, order_opt)\n",
    "    \n",
    "    # Predict \n",
    "    y_pred = testRBFDiffNet(X_val, weights, centres, betas)\n",
    "    \n",
    "\n",
    "   # Error metrics\n",
    "    rmsse = np.sqrt(MSE(y_val, y_pred)/denom)\n",
    "    r2 = R2(y_val, y_pred)\n",
    "    rmse = MSE(y_val, y_pred, squared=False)\n",
    "    mae = MAE(y_val, y_pred)\n",
    "    \n",
    "    results.append([rmsse, rmse, r2, mae])\n",
    "    \n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.rename(index={results_df.index[i]: level3_data.index[i] for i in range(10)}, columns={0: 'RMSSE', 1: 'RMSE', 2: 'R2', 3:'MAE'})\n",
    "print('mean results:', np.mean(results_df.values, axis=0))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning across the series with RBF-DiffNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = pd.DataFrame()\n",
    "ytrain = pd.DataFrame()\n",
    "Xval = pd.DataFrame()\n",
    "yval = pd.DataFrame()\n",
    "store_count = 0\n",
    "for store_id in level3_data.index:\n",
    "    X, y = data_dict[store_id]\n",
    "    X_train, y_train, X_val, y_val = X[0:-28, :], y[0:-28, :], X[-28:, :], y[-28:, :]\n",
    "    \n",
    "    if store_id.split('_')[0] == 'CA':\n",
    "        state_id = 1\n",
    "    elif store_id.split('_')[0] == 'TX':\n",
    "        state_id = 2\n",
    "    elif store_id.split('_')[0] == 'WI':\n",
    "        state_id = 3\n",
    "    \n",
    "    X_train = np.column_stack((store_count*np.ones([X_train.shape[0],1],dtype='int64'), state_id*np.ones([X_train.shape[0],1],dtype='int64'), X_train))\n",
    "    X_val = np.column_stack((store_count*np.ones([X_val.shape[0],1],dtype='int64'), state_id*np.ones([X_val.shape[0],1],dtype='int64'), X_val))\n",
    "    \n",
    "    Xtrain = pd.concat([Xtrain, pd.DataFrame(X_train)])\n",
    "    ytrain = pd.concat([ytrain, pd.DataFrame(y_train)])\n",
    "    \n",
    "    Xval = pd.concat([Xval, pd.DataFrame(X_val)])\n",
    "    yval = pd.concat([yval, pd.DataFrame(y_val)])\n",
    "    \n",
    "    store_count = store_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting RBF-DiffNet\n",
    "\n",
    "order_opt = 1\n",
    "nlags = 2\n",
    "c = 50\n",
    "\n",
    "weights, centres, betas = trainRBFDiffNet(Xtrain.values, ytrain.values, c, nlags, order_opt)\n",
    "yhat = testRBFDiffNet(Xval.values, weights, centres, betas)\n",
    "YHAT = yhat.reshape(10,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error metrics\n",
    "results = []\n",
    "for i in range(10):\n",
    "    #RMSSE denominator\n",
    "    store_id = level3_data.index[i]\n",
    "    X, y = data_dict[store_id]\n",
    "    X_train, y_train, X_val, y_val = X[0:-28, :], y[0:-28, :], X[-28:, :], y[-28:, :]\n",
    "    \n",
    "    ytrain = level3_data.loc[store_id,:].values[0:-28]\n",
    "    denom = np.mean(np.diff(ytrain.flatten())**2)\n",
    "    \n",
    "    y_pred = YHAT[i,:]\n",
    "    # Error metrics\n",
    "    rmsse = np.sqrt(MSE(y_val, y_pred)/denom)\n",
    "    r2 = R2(y_val, y_pred)\n",
    "    rmse = MSE(y_val, y_pred, squared=False)\n",
    "    mae = MAE(y_val, y_pred) \n",
    "    results.append([rmsse, rmse, r2, mae])\n",
    "    \n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.rename(index={results_df.index[i]: level3_data.index[i] for i in range(10)}, columns={0: 'RMSSE', 1: 'RMSE', 2: 'R2', 3:'MAE'})\n",
    "print('mean results:', np.mean(results_df.values, axis=0))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
